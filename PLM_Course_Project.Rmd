---
title: "PLM Course Project"
author: "Nino Munoz"
date: "February 27, 2016"
output: html_document
---

### Background

Using devices such as *Jawbone Up*, *Nike FuelBand* and *Fitbit*, it is now possible to collect a large amount of data about personal acivity relatively inexpensively. These types of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different wawys. More information is available from the website [here](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).

### Data

The training data for this project are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv).

The test data are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv).

The data for this project come from [this source](http://groupware.les.inf.puc-rio.br/har).

### Objective

The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. We will describe:

1. How we build the model
2. How we use cross-validation
3. What we think the expected out-of-sample error is
4. Steps taken during our analysis

### Loading the Data

1. Load required libraries.

```{r loadlibraries, message = FALSE}
library(abind)
library(arm)
library(caret)
library(doMC)
library(kernlab)
library(klaR)
library(randomForest)
library(rpart)
```

```{r registercores}
registerDoMC(cores = 3)
```

2. Set the seed so that analysis can be reproduced.

```{r setseed}
set.seed(12345)
```

3. Load data into memory.

```{r loaddata, cache = TRUE}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

train <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
test <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```

### Preprocessing the Data

1. Remove variables with near-zero variance.

```{r nzv, cache = TRUE}
nearzero <- nearZeroVar(train, saveMetrics = TRUE)
train <- train[, !nearzero$nzv]
```

2. Remove variables with too many missing values (more than 50% NA's).

```{r removenas, cache = TRUE}
missing <- sapply(colnames(train), function(x) sum(is.na(train[, x])) > (0.50 * nrow(train)))
train <- train[, !missing]
```

3. Remove irrelevant variables.

```{r removeirrelevant, cache = TRUE}
train <- train[, -(1:6)]
```

### Building the Model & Cross-Validation

Three models will be estimated: Random Forest, Bayes Generalized Linear Model, and Logit Boosted mode. The model with the highest accuracy will be chosen as our final model.

1. In order to avoid overfitting, and to reduce out-of-sample error, we will use the trainControl method to perform 7-fold cross validation.

```{r traincontrol, cache = TRUE}
tc <- trainControl(method = "cv", number = 7, verboseIter = FALSE, preProcOptions = "pca", allowParallel = TRUE)
```

2. Generate models of the training data set.

```{r models, cache = TRUE, message = FALSE, warning = FALSE}
rf <- train(classe ~ ., data = train, method = "rf", trControl = tc) # random forest
bayesglm <- train(classe ~ ., data = train, method = "bayesglm", trControl = tc) # bayes glm
logitboost <- train(classe ~ ., data = train, method = "LogitBoost", trControl = tc) # logit boosted
```

3. Compare accuracy of each model.

```{r accuracies, cache = TRUE}
Model <- c("Random Forest", "Bayes GLM","LogitBoost")
Accuracy <- c(max(rf$results$Accuracy),
        max(bayesglm$results$Accuracy),
        max(logitboost$results$Accuracy))
comparison <- cbind(Model, Accuracy)
knitr::kable(comparison)
```

***

*With an accuracy of 99.5%, the Random Forest model gives the most accurate predictions on the training set.*

***

### Prediction

1. Using the Random Forest model fit from our training set, we can use the predict function on our test data set.

```{r rfpredict, cache = TRUE}
## Random forest predictions
rf.predictions <- predict(rf, test)
```

2. We can cross-validate our predictions by comparing them to the predictions given by our next best model, Logit Boosted.

```{r logitpredict, cache = TRUE}
## Logit Boosted predictions
logitboost.predictions <- predict(logitboost, test)

## Calculate percentage of matching predictions
same <- rf.predictions == logitboost.predictions
same <- same[!is.na(same)]
sum(same) / length(same)
```

***

*On the test dataset, Random forest and Logit Boosted models give the same prediction 81.25% of the time.*

***

3. Below are our predictions for the 20 test cases:

```{r predictions}
rf.predictions
```